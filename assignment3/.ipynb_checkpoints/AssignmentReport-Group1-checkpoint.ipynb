{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](plots\\1add.png)\n",
    "\n",
    "## task 1b)\n",
    "\n",
    "Max Pooling\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "![](plots\\1c.png)\n",
    "\n",
    "## task 1d)\n",
    "\n",
    "![](plots\\1d.png)\n",
    "\n",
    "## task 1e)\n",
    "\n",
    "![](plots\\1e.png)\n",
    "\n",
    "## task 1f)\n",
    "\n",
    "![](plots\\1f.png)\n",
    "\n",
    "## task 1g)\n",
    "\n",
    "![](plots\\1g.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2a)\n",
    "![](plots\\Task2a3.png)\n",
    "\n",
    "### Task 2b)\n",
    "Training accuracy: 0.8\\\n",
    "Validation accuracy: 0.745  \n",
    "Test accuracy: 0.743 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "\n",
    "Bot models used both batch normalization and regulation with dropout with same probobility of 0.2 after each activation on the convelutional layers. Parameter values for each layer can be found in table (like padding, kernal size and stride). First model has 3 layer of convolution and second model used 4. There was not mutch benefit.\n",
    "![](plots\\3a.png)\n",
    "\n",
    "### Task 3b)\n",
    "![](plots\\table3b.png)\n",
    "![](plots\\Task3Modell2.png)\n",
    "\n",
    "### Task 3c)\n",
    "Filter size: I found small improvments changeing the filtersize to 3 and match the padding setting it to 1. I am not sure, but it might have something to do with the filter being more focused. I tought it might be smart to increase the size of the filter in later layer, so small features could be \"put togheter\". This dident improve the cnn.\n",
    "\n",
    "Number of filters: I tried with more and the effect was minimal based on the amount of time that was added. Less didnt help either.\n",
    "\n",
    "Batch normalization: Helped a good amount.\n",
    "\n",
    "Regularization: Mostly help to not overtrain the model.\n",
    "\n",
    "Activation function: I tried swapping out Relu for sigmoid in both convolutional layers and fully connected layer. In the conv layer it made the model sligthly worse and no real effect in the fully connected layer.\n",
    "\n",
    "Filter structure: I tried with an extra layer of 256 filters, made Model2 slightly better then model 1.\n",
    "\n",
    "### Task 3d)\n",
    "![](plots\\3d.png)\n",
    "\n",
    "### Task 3e)\n",
    "With a lot of tries I got Model2 to hit 79.54 prosent. After all the time I spent on it I desided that today 79.54 >= 80. To reach this I added an extra fully connected layer with 32 nuerons and used regularozation and batch normlization on the fully connected layers as well.\n",
    "![](plots\\3e.png)\n",
    "\n",
    "### Task 3f)\n",
    "Both losses seem to flatten out at the same values. Hence it does not seem to be over or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "Learing rate = 5*10^-1, batch size = 32. No adamoptimizer as i dident get it to work.\n",
    "Note: I used resolution 112*112 to reduce trainingtime.\n",
    "![](plots\\Task4a.png)\n",
    "\n",
    "## Task 4b)\n",
    "Its look like filter 1 lookes for vertical edges, filter 2 looks for horizontal egdes, the other ones is hard to say anything about. Form the activations it looks like image 1, 2 and 4 visulize the egdes of the image. While 3 and 5 are detecting object (here we see sky, ground and zebra) with inverted colors to each other.\n",
    "![](plots\\4b.png)\n",
    "\n",
    "## Task 4c)\n",
    "I tried, but I didnt find a way to get the filters from the model.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
