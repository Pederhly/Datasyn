On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   ssd/modeling/backbones/basic.py
	modified:   train.py
	modified:   ../precision_recall_curve.png

no changes added to commit (use "git add" and/or "git commit -a")
869781b33aa6158293f2ab316448f804a790a07c
diff --git a/assignment4/SSD/ssd/modeling/backbones/basic.py b/assignment4/SSD/ssd/modeling/backbones/basic.py
index 430fc7e..717f9df 100644
--- a/assignment4/SSD/ssd/modeling/backbones/basic.py
+++ b/assignment4/SSD/ssd/modeling/backbones/basic.py
@@ -1,4 +1,5 @@
 import torch
+import torch.nn as nn
 from typing import Tuple, List
 
 
@@ -21,6 +22,60 @@ class BasicModel(torch.nn.Module):
         self.out_channels = output_channels
         self.output_feature_shape = output_feature_sizes
 
+        self.L1 = nn.Sequential(
+            # Layer 1
+            nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.MaxPool2d(kernel_size = 2, stride = 2),
+            nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.MaxPool2d(kernel_size = 2, stride = 2),
+            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.Conv2d(in_channels = 64, out_channels = output_channels[0], kernel_size = 3, stride = 2, padding = 1),
+            nn.ReLU()
+            )
+        self.L2 = nn.Sequential(
+            # Layer 2
+            nn.ReLU(),
+            nn.Conv2d(in_channels = output_channels[0], out_channels = 128, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.Conv2d(in_channels = 128, out_channels = output_channels[1], kernel_size = 3, stride = 2, padding = 1),
+            nn.ReLU()
+        )
+        self.L3 = nn.Sequential(
+            # Layer 3
+            nn.ReLU(),
+            nn.Conv2d(in_channels = output_channels[1], out_channels = 256, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.Conv2d(in_channels = 256, out_channels = output_channels[2], kernel_size = 3, stride = 2, padding = 1),
+            nn.ReLU()
+        )
+        self.L4 = nn.Sequential(
+            # Layer 4
+            nn.ReLU(),
+            nn.Conv2d(in_channels = output_channels[2], out_channels = 128, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.Conv2d(in_channels = 128, out_channels = output_channels[3], kernel_size = 3, stride = 2, padding = 1),
+            nn.ReLU()
+        )
+        self.L5 = nn.Sequential(
+            #Layer 5
+            nn.ReLU(),
+            nn.Conv2d(in_channels = output_channels[3], out_channels = 128, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.Conv2d(in_channels = 128, out_channels = output_channels[4], kernel_size = 3, stride = 2, padding = 1),
+            nn.ReLU()
+        )
+        self.L6 = nn.Sequential(
+            # Layer 6
+            nn.ReLU(),
+            nn.Conv2d(in_channels = output_channels[4], out_channels = 128, kernel_size = 3, stride = 1, padding = 1),
+            nn.ReLU(),
+            nn.Conv2d(in_channels = 128, out_channels = output_channels[5], kernel_size = 3, stride = 1, padding = 0),
+            nn.ReLU()
+        )
+
     def forward(self, x):
         """
         The forward functiom should output features with shape:
@@ -34,7 +89,16 @@ class BasicModel(torch.nn.Module):
         where out_features[0] should have the shape:
             shape(-1, output_channels[0], 38, 38),
         """
-        out_features = []
+        out0 = x
+        out1 = self.L1(out0)
+        out2 = self.L2(out1)
+        out3 = self.L3(out2)
+        out4 = self.L4(out3)
+        out5 = self.L5(out4)
+        out6 = self.L6(out5)
+
+        out_features = [out1, out2, out3, out4, out5, out6]
+
         for idx, feature in enumerate(out_features):
             out_channel = self.out_channels[idx]
             h, w = self.output_feature_shape[idx]
diff --git a/assignment4/SSD/train.py b/assignment4/SSD/train.py
index 91302b3..d6d39f4 100644
--- a/assignment4/SSD/train.py
+++ b/assignment4/SSD/train.py
@@ -12,6 +12,7 @@ from ssd import utils
 from tops.config import instantiate
 from tops import logger, checkpointer
 from torch.optim.lr_scheduler import ChainedScheduler
+from omegaconf import OmegaConf
 torch.backends.cudnn.benchmark = True
 
 def train_epoch(
@@ -50,7 +51,7 @@ def train_epoch(
 
 
 @click.command()
-@click.argument("config_path", type=click.Path(exists=True, dir_okay=False, path_type=Path))
+@click.argument("config_path", type=click.Path(exists=True, dir_okay=False, path_type=str)) # Path
 @click.option("--evaluate-only", default=False, is_flag=True, help="Only run evaluation, no training.")
 def train(config_path: Path, evaluate_only: bool):
     logger.logger.DEFAULT_SCALAR_LEVEL = logger.logger.DEBUG
diff --git a/assignment4/precision_recall_curve.png b/assignment4/precision_recall_curve.png
index 812a389..08cd9e6 100644
Binary files a/assignment4/precision_recall_curve.png and b/assignment4/precision_recall_curve.png differ
